{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_2_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U55FlaVTaLss"
      },
      "outputs": [],
      "source": [
        "# Usual data representation and manipulation libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Evaluation libraries\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Libraries for feature engineering\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation, Embedding\n",
        "from tensorflow.keras.layers import Dropout, Activation, SpatialDropout1D\n",
        "#from tensorflow.keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence,text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzn2RXv_c277",
        "outputId": "f4a1d4ab-a6e1-45e0-d70e-18b09f16bd09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_food_reviews = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/normalized_food_review.csv\")\n",
        "\n",
        "max_fet = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fet, split=' ')\n",
        "tokenizer.fit_on_texts(normalized_food_reviews['review'].iloc[:15000].values)\n",
        "X = tokenizer.texts_to_sequences(normalized_food_reviews['review'].iloc[:15000].values)\n",
        "#tokenizer.fit_on_texts(normalized_food_reviews['review'].values)\n",
        "#X = tokenizer.texts_to_sequences(normalized_food_reviews['review'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "y = pd.get_dummies(normalized_food_reviews[\"sentiment\"].iloc[:15000]).values\n",
        "\n",
        "\n",
        "# extract data for model evaluation the training and test is split into 70% and 30%\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "print(\"Shape X_train: {}, Shape of X_test: {}\".format(X_train.shape, X_test.shape))\n",
        "print(\"Shape Y_train: {}, Shape of Y_test: {}\".format(Y_train.shape, Y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ovF0xraaeK",
        "outputId": "6d981c07-2713-44a8-c377-6a5edc07c126"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_train: (10500, 697), Shape of X_test: (4500, 697)\n",
            "Shape Y_train: (10500, 2), Shape of Y_test: (4500, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fet, embed_dim, input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwX0KrV9dPEQ",
        "outputId": "f0e42738-5018-4472-cf73-db04e568d8ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 697, 128)          256000    \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 697, 128)         0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               91600     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347,802\n",
            "Trainable params: 347,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r1HxF5kdXx_",
        "outputId": "813e06ff-d6e6-45d1-bb6d-ed33d76ea670"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "329/329 - 548s - loss: 0.4958 - accuracy: 0.7615 - 548s/epoch - 2s/step\n",
            "Epoch 2/10\n",
            "329/329 - 497s - loss: 0.3646 - accuracy: 0.8439 - 497s/epoch - 2s/step\n",
            "Epoch 3/10\n",
            "329/329 - 499s - loss: 0.3103 - accuracy: 0.8741 - 499s/epoch - 2s/step\n",
            "Epoch 4/10\n",
            "329/329 - 502s - loss: 0.2731 - accuracy: 0.8898 - 502s/epoch - 2s/step\n",
            "Epoch 5/10\n",
            "329/329 - 496s - loss: 0.2411 - accuracy: 0.9054 - 496s/epoch - 2s/step\n",
            "Epoch 6/10\n",
            "329/329 - 496s - loss: 0.2139 - accuracy: 0.9159 - 496s/epoch - 2s/step\n",
            "Epoch 7/10\n",
            "329/329 - 498s - loss: 0.1950 - accuracy: 0.9213 - 498s/epoch - 2s/step\n",
            "Epoch 8/10\n",
            "329/329 - 490s - loss: 0.1721 - accuracy: 0.9327 - 490s/epoch - 1s/step\n",
            "Epoch 9/10\n",
            "329/329 - 499s - loss: 0.1635 - accuracy: 0.9359 - 499s/epoch - 2s/step\n",
            "Epoch 10/10\n",
            "329/329 - 486s - loss: 0.1430 - accuracy: 0.9454 - 486s/epoch - 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb65ebb2550>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lstm = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "nn5PamHz091O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3ppnNaTG8dV",
        "outputId": "b268a690-7e87-463f-b38a-64c330d1e531"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.callbacks.History object at 0x7fb65a7e4390>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJfIejc_HLbz",
        "outputId": "974c2124-9e39-476f-f565-ee697ad74101"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141/141 - 25s - loss: 0.6364 - accuracy: 0.8024 - 25s/epoch - 176ms/step\n",
            "score: 0.64\n",
            "acc: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_arg=np.argmax(Y_test,axis=1)\n",
        "Y_pred_lstm = np.argmax(model.predict(X_test),axis=1)\n",
        "print('Confusion Matrix')\n",
        "cf_matrix=confusion_matrix(y_test_arg, Y_pred_lstm)\n",
        "print(cf_matrix)\n",
        "\n",
        "f1_score_calc = cf_matrix[0][0] / (cf_matrix[0][0] + 0.5 * (cf_matrix[0][1] + cf_matrix[1][0]))\n",
        "print('F1-score: %.3f' % f1_score_calc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbSipc9h1F7N",
        "outputId": "e2de030e-121d-4a0e-d8b1-278b05c32ecd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[1725  515]\n",
            " [ 374 1886]]\n",
            "F1-score: 0.795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LSTM - Amazon review sentiment analysis\")\n",
        "print(\"The model accuracy score is: {}\".format(accuracy_score(y_test_arg, Y_pred_lstm)))\n",
        "print(\"The model precision score is: {}\".format(precision_score(y_test_arg, Y_pred_lstm, average=\"weighted\")))\n",
        "print(\"The model recall score is: {}\".format(recall_score(y_test_arg, Y_pred_lstm, average=\"weighted\")))\n",
        "print(\"The model F1-score is: {}\".format(f1_score(y_test_arg, Y_pred_lstm, average=\"weighted\")))\n",
        "\n",
        "print(classification_report(y_test_arg, Y_pred_lstm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TO3rMgnVSjg",
        "outputId": "463249fa-4bff-4071-90b0-288d9b9c27de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM - Amazon review sentiment analysis\n",
            "The model accuracy score is: 0.8024444444444444\n",
            "The model precision score is: 0.8035822791974062\n",
            "The model recall score is: 0.8024444444444444\n",
            "The model F1-score is: 0.8022226934976316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.77      0.80      2240\n",
            "           1       0.79      0.83      0.81      2260\n",
            "\n",
            "    accuracy                           0.80      4500\n",
            "   macro avg       0.80      0.80      0.80      4500\n",
            "weighted avg       0.80      0.80      0.80      4500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment"
      ],
      "metadata": {
        "id": "1GPOV6VzWJV1"
      }
    }
  ]
}