{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Task_2_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U55FlaVTaLss"
      },
      "outputs": [],
      "source": [
        "# Usual data representation and manipulation libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Evaluation libraries\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Libraries for feature engineering\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation, Embedding\n",
        "from tensorflow.keras.layers import Dropout, Activation, SpatialDropout1D\n",
        "#from tensorflow.keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence,text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzn2RXv_c277",
        "outputId": "483bead0-dc43-4c55-9f36-1bd73ca7918a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_food_reviews = pd.read_csv(\"/content/drive/MyDrive/Colab_Notebooks/normalized_food_review.csv\")\n",
        "\n",
        "max_fet = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fet, split=' ')\n",
        "#tokenizer.fit_on_texts(normalized_food_reviews['review'].iloc[:15000].values)\n",
        "#X = tokenizer.texts_to_sequences(normalized_food_reviews['review'].iloc[:15000].values)\n",
        "tokenizer.fit_on_texts(normalized_food_reviews['review'].values)\n",
        "X = tokenizer.texts_to_sequences(normalized_food_reviews['review'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "#y = pd.get_dummies(normalized_food_reviews[\"sentiment\"].iloc[:15000]).values\n",
        "y = pd.get_dummies(normalized_food_reviews[\"sentiment\"]).values\n",
        "\n",
        "\n",
        "# extract data for model evaluation the training and test is split into 70% and 30%\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "print(\"Shape X_train: {}, Shape of X_test: {}\".format(X_train.shape, X_test.shape))\n",
        "print(\"Shape Y_train: {}, Shape of Y_test: {}\".format(Y_train.shape, Y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ovF0xraaeK",
        "outputId": "ce82e01a-07d7-4732-9c75-c35f9c446137"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_train: (35000, 692), Shape of X_test: (15000, 692)\n",
            "Shape Y_train: (35000, 2), Shape of Y_test: (15000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fet, embed_dim, input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwX0KrV9dPEQ",
        "outputId": "9cd53905-ec82-40e3-8356-5f8f735c5be0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 692, 128)          256000    \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 692, 128)         0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               91600     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347,802\n",
            "Trainable params: 347,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "model.history = model.fit(X_train, Y_train, epochs = 2, batch_size=batch_size, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r1HxF5kdXx_",
        "outputId": "d26c0ff6-3d3a-449a-d4de-12a75c88143f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "350/350 - 938s - loss: 0.4372 - accuracy: 0.7968 - 938s/epoch - 3s/step\n",
            "Epoch 2/2\n",
            "350/350 - 922s - loss: 0.3559 - accuracy: 0.8466 - 922s/epoch - 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lstm = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "nn5PamHz091O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3ppnNaTG8dV",
        "outputId": "e6e60ef0-61a0-4725-ef87-85a26a6b4fc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.callbacks.History object at 0x7f38b32f6cd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Metrics"
      ],
      "metadata": {
        "id": "4M6kutafszrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJfIejc_HLbz",
        "outputId": "279646fb-4eac-41b3-faa5-24b7f125a074"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 63s - loss: 0.3554 - accuracy: 0.8463 - 63s/epoch - 420ms/step\n",
            "score: 0.36\n",
            "acc: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_arg=np.argmax(Y_test,axis=1)\n",
        "Y_pred_lstm = np.argmax(model.predict(X_test),axis=1)\n",
        "print('Confusion Matrix')\n",
        "cf_matrix=confusion_matrix(y_test_arg, Y_pred_lstm)\n",
        "print(cf_matrix)\n",
        "\n",
        "f1_score_calc = cf_matrix[0][0] / (cf_matrix[0][0] + 0.5 * (cf_matrix[0][1] + cf_matrix[1][0]))\n",
        "print('F1-score: %.3f' % f1_score_calc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbSipc9h1F7N",
        "outputId": "89e74d0e-aaae-4724-bbd1-a88229333ffc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[6667  905]\n",
            " [1401 6027]]\n",
            "F1-score: 0.853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LSTM - Amazon review sentiment analysis\")\n",
        "print(\"The model accuracy score is: {}\".format(accuracy_score(y_test_arg, Y_pred_lstm)))\n",
        "print(\"The model precision score is: {}\".format(precision_score(y_test_arg, Y_pred_lstm, average=\"weighted\")))\n",
        "print(\"The model recall score is: {}\".format(recall_score(y_test_arg, Y_pred_lstm, average=\"weighted\")))\n",
        "print(\"The model F1-score is: {}\".format(f1_score(y_test_arg, Y_pred_lstm, average=\"weighted\")))\n",
        "\n",
        "print(classification_report(y_test_arg, Y_pred_lstm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TO3rMgnVSjg",
        "outputId": "459036f9-d9bc-4dd6-e5e2-e18c7841cf9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM - Amazon review sentiment analysis\n",
            "The model accuracy score is: 0.8462666666666666\n",
            "The model precision score is: 0.8476916756902738\n",
            "The model recall score is: 0.8462666666666666\n",
            "The model F1-score is: 0.8460493772841581\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85      7572\n",
            "           1       0.87      0.81      0.84      7428\n",
            "\n",
            "    accuracy                           0.85     15000\n",
            "   macro avg       0.85      0.85      0.85     15000\n",
            "weighted avg       0.85      0.85      0.85     15000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment"
      ],
      "metadata": {
        "id": "1GPOV6VzWJV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(model, open('lstmModel.pkl', 'wb'))\n",
        " \n",
        "model1 = pickle.load(open('lstmModel.pkl', 'rb'))\n",
        " \n",
        "#model.predict(patient1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvt2gX_fzt1d",
        "outputId": "182242d4-cd3c-41d5-db88-677936a0ab08"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://d2bab468-dd6a-4119-bef9-de32888adfef/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://d2bab468-dd6a-4119-bef9-de32888adfef/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f38b2ef2850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/lstmModel.pkl"
      ],
      "metadata": {
        "id": "WJ7mo6XiiiWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from sqlalchemy import create_engine\n",
        "engine = create_engine('sqlite:///'+ \"AmaxonFoodReview.db\")\n",
        "\n",
        "normalized_food_reviews = normalized_food_reviews.drop(columns =[\"Review\"])\n",
        "normalized_food_reviews.to_sql('AmaxonFoodReview', engine, if_exists='replace', index=False)"
      ],
      "metadata": {
        "id": "RW03nTRRjKbe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        " \n",
        "joblib.dump(model, 'model_save2')\n",
        " \n",
        "model2 = joblib.load('model_save2')\n",
        " \n",
        "#model2.predict(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiNwrqSifU3L",
        "outputId": "4576830d-be67-45de-b938-918d259d1db7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://04ad5944-07bd-4fc0-8b2e-a0afdaf2c8c0/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://04ad5944-07bd-4fc0-8b2e-a0afdaf2c8c0/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f38b2ef2850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    }
  ]
}